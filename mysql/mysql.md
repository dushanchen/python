https://zhuanlan.zhihu.com/p/1950606418622288824

1. B-tree 和B+tree
    B+tree的非叶子节点只存储索引，叶子节点存储数据本身，叶子节点连成双向链表，范围查询非常快。
2. 什么字段适合建立索引
    主键、外键，主键自动建立索引，外键在外键约束声明情况下自动建立索引。
    经常join的字段、order by、group by 的字段，值得建立索引
    高选择性的字段适合建立索引，低选择性字段（比如性别、状态）不适合建立索引

    不适合建立索引的字段：
        需要频繁改动的字段，频繁更新索引会非常消耗性能
        很少被用于查询的字段
        数据量极小的表（<1万行)，全表扫描更快
        非常长的字段（超长varchar、text类型），考虑前缀索引
        低选择性字段
2. 最左前缀匹配原则
    一个针对 (col1, col2, col3) 的复合索引，相当于同时创建了以下三个索引：
    (col1)
    (col1, col2)
    (col1, col2, col3)
    一个经典的技巧是：将等值查询的字段放在前面，范围查询的字段放在后面。

3. 联合索引，范围查询索引失效，也可能索引生效

4. 覆盖索引

5. 联合索引，排序查询、

6. 索引失效的各种情况

7. mysql锁

8. 慢查询如何优化

9. 聚簇索引和非聚簇索引
    数据和索引放在一起

10. 如何实现分开分表
    垂直切分、水平切分
    唯一主键问题： 双buffer方案、雪花算法

11. ACID靠什么保证
    A 原子性，有undo log保证
    C 由其他三个保证
    I 隔离性有MVCC保证
    D 持久性，由内存和redo log保证

12. MVCC
    RC 和 RR 隔离级别下工作
    聚簇索引隐藏列：trx_id、roll_pointer

13. mysql主从同步原理
    全同步复制、半同步复制

14. 事务的特性和隔离级别

## 1. 基础面试题
### 1.1 数据库的三范式是什么？

    数据库的三范式是我们在设计表结构时需要遵循的一些基本原则，主要是为了减少数据冗余，保证数据的一致性。

    第一范式是最基础的，它要求表里的每一列都必须是不可再分的原子项。比如说，一个“联系方式”字段里不能同时存手机和座机，必须拆成两个独立的字段。
    第二范式是建立在第一范式之上的，它要求表里的非主键列必须完全依赖于整个主键，而不是主键的一部分。这通常是针对联合主键的情况，防止出现部分依赖。
    第三范式则更进一步，要求非主键列之间不能存在传递依赖。也就是说，一个非主键列不能依赖于另一个非主键列。

    在实际开发中，我们通常会遵守这三个范式，但有时候为了查询性能，也会做一些反范式的设计，比如增加一些冗余字段来避免复杂的表连接。

### 1.2 MySQL 支持哪些存储引擎?
    MySQL支持很多种存储引擎，最常用的就是InnoDB和MyISAM，此外还有Memory、Archive等。在绝大多数情况下，我们都会选择InnoDB，它现在也是MySQL的默认存储引擎了。

### 1.3 MySQL中MyISAM与InnoDB的区别是什么?
    关于MyISAM和InnoDB的主要区别，我认为最核心的一点在于对事务的支持。InnoDB是支持事务的，并且实现了ACID特性，这让它非常适合需要高可靠性的场景，比如在线交易。为了支持事务，InnoDB还提供了行级锁和MVCC，这在高并发读写下性能表现很好。

    而MyISAM则不支持事务，它使用的是表级锁，写操作会锁住整张表，所以在写入并发量大的时候性能会比较差，但它的结构相对简单，读取速度很快，所以比较适合一些读多写少的应用场景。

    其他方面，像InnoDB支持外键，而MyISAM不支持；MyISAM曾经在全文索引上有优势，不过现在新版的InnoDB也支持了。总的来说，现在InnoDB是更主流的选择，尤其是在对数据一致性和并发性要求高的业务里。

### 1.4 MySQL 中的 varchar 和 char 有什么区别？
    char和varchar最主要的区别在于存储方式。char是定长的，比如你定义了char(10)，那就算你只存了一个字符'a'，它在磁盘上也会占用10个字符的空间，剩下的会用空格补齐。而varchar是变长的，它会根据你实际存储内容的长度来分配空间，同时还需要额外1到2个字节来记录内容的实际长度。
    从性能上讲，因为char是定长的，处理起来会比varchar稍微快一点。所以在选择时，如果一个字段的长度是完全固定的，比如像MD5加密后的密码（32位）、或者手机号这种，用char会更合适。但对于大多数长度不确定的字段，比如用户名、地址等，用varchar会更节省存储空间。

### 1.5 MySQL中DATETIME 和 TIMESTAMP有什么区别？
    DATETIME 直接存储日期和时间的完整值，与时区无关。
    TIMESTAMP 存储的是 Unix 时间戳，1970-01-01 00:00:01 UTC 以来的秒数，受时区影响。

    另外，DATETIME 的默认值为 null，占用 8 个字节；TIMESTAMP 的默认值为当前时间——CURRENT_TIMESTAMP，占 4 个字节，实际开发中更常用，因为可以自动更新。

### 1.6 MySQL中 in 和 exists 区别？
    in和exists主要用在子查询中，它们的执行逻辑不太一样，导致性能上在不同场景下有差异。

    简单来说，有一个通用的判断法则是：小表驱动大表。

    如果子查询（内表）的结果集比较小，主查询（外表）的表比较大，那么用in的效率会比较高。因为in会先执行子查询，然后把结果缓存起来，再去主查询的表里匹配。

    反过来，如果子查询的表很大，主查询的表很小，那么用exists会更好。因为exists是拿主查询表里的每一行记录，去子查询的表里做一个判断，看是否存在匹配。

    另外，对于not in和not exists，一般推荐使用not exists，因为not in在很多情况下无法有效利用索引，会导致全表扫描。

### 1.7 删除表的时候drop、delete与truncate的区别是什么？
    这三个命令都是用来删除数据的，但它们的级别和行为完全不同。
    delete是DML语言，它是一行一行地删除记录，可以带WHERE子句只删除部分数据。因为是事务性操作，所以delete的删除是可以回滚的，并且会触发触发器。
    truncate是DDL语言，它会直接删除表里的所有数据，保留表结构，不能带WHERE子-句。它相当于重建了表，所以速度非常快，不能回滚，也不会触发触发器。
    drop也是DDL语言，它是最彻底的，会直接把整张表，包括表结构、数据、索引、约束等全部从数据库里删除掉，当然也不能回滚。

    下表是三种方式的一个对比：
    分类	Delete	        Truncate	       Drop
    类型	属于 DML	     属于 DDL	        属于 DDL
    回滚	可回滚	         不可回滚	         不可回滚
    删除内容	表结构还在，删除表的全部或者部分数据行	表结构还在，删除表中的所有数据	从数据库中删除表，所有的数据行、索引和权限也会被删除
    删除速度  删除速度慢，需要逐行删除	删除速度快	删除速度最快

### 1.8 什么是存储过程？有哪些优缺点？？
    存储过程可以理解为是一段预先编译好的SQL代码集合，我们给它起一个名字，之后就可以像调用一个函数一样来调用它，执行这一整套SQL操作。
    它的优点很明显：首先，因为是预编译的，所以执行效率会比单条SQL语句高；其次，它可以把复杂的业务逻辑封装在数据库层面，减少了客户端和数据库之间的网络通信；另外，还能在一定程度上提高数据的安全性。
    
    不过，它的缺点也很突出，尤其是在现在快速迭代的互联网项目中。存储过程的可移植性很差，如果换数据库，基本等于重写。而且，它的维护和调试也比较麻烦，业务逻辑都耦合在数据库里，对后续的扩展和版本管理都不太友好。所以像阿里的开发手册里，是明确禁止使用存储过程的。

### 1.9 对Mysql并发操作可能带来哪些问题？
    并发操作如果隔离做得不好，主要会带来几个问题。
    首先是脏读，就是一个事务读到了另一个事务还没提交的数据，这个数据可能后面会回滚，所以是“脏”的。
    然后是不可重复读，指的是在同一个事务里，两次查询同一条数据，结果不一样，这是因为中间有别的事务把这条数据给修改并提交了。
    最后是幻读，跟不可重复读有点像，但它关注的是数据条数的变化。比如我第一次查有10条记录，第二次查就变成了11条，多出来的就像幻觉一样，这是因为中间有别的事务插入了新的数据。

### 1.10 MyISAM和InnoDB实现B-Tree索引方式的区别

    MyISAM和InnoDB虽然都用B+树，但实现上差别很大。MyISAM用的是非聚集索引，它的索引文件和数据文件是分开的。索引树的叶子节点存的是数据记录的物理地址，找到索引后还要根据地址再去数据文件里捞数据。

    而InnoDB是索引组织表，它的数据文件本身就是一棵B+树，也就是聚集索引，通常就是主键索引。这棵树的叶子节点直接包含了完整的行数据。所以按主键查InnoDB会非常快。它的普通索引（或者叫二级索引）的叶子节点存的不是地址，而是主键的值。所以用普通索引查询时，需要先找到主键值，再用主键值去聚集索引里找一遍数据，这个过程也叫“回表”。

### 1.11 MySQL建表的约束条件有哪些？

    MySQL建表时我们常用的约束主要有这么几种：

        主键约束 (PRIMARY KEY)：保证唯一并且非空。
        唯一约束 (UNIQUE)：只保证唯一，可以有一个NULL。
        非空约束 (NOT NULL)：就是这列不能为空。
        默认约束 (DEFAULT)：给一个默认值。
        外键约束 (FOREIGN KEY)：用来关联两个表，保证数据的一致性。
        检查约束 (CHECK)：新一点的MySQL版本也支持了，可以对值进行校验。
    
### 1.12 MySQL执行查询的过程
    客户端 -> 连接器 -> 查询缓存 -> 解析器 -> 优化器 -> 执行器 -> 存储引擎 -> 数据 -> 客户端
    连接器：权限验证、连接管理
    解析器：语法解析，生成解析树
    优化器：决定有什么索引查询、表的连接顺序等
    执行器：调用存储引擎接口，获取数据

## 2. 事务面试题
### 2.1 什么是数据库事务？
一组必须作为一个整体来执行的数据库操作。这些操作要么全部成功执行，要么在任何一步出错的情况下，全部回滚到最初的状态

### 2.2 事务的ACID特性
**A - Atomicity (原子性)**：这是指事务是一个不可分割的整体，里面的所有操作要么全部完成，要么全部不完成。
**C - Consistency (一致性)**：指的是事务必须使数据库从一个一致的状态转移到另一个一致的状态。在事务开始前和结束后，数据库的完整性约束没有被破坏。
**I - Isolation (隔离性)**：这个主要是针对并发场景的。它保证一个事务的执行不能被其他事务干扰，多个并发事务之间要相互隔离。
**D - Durability (持久性)**：指的是一个事务一旦被提交，它对数据库中数据的改变就是永久性的，即使后面系统崩溃也不会丢失。

### 2.3 MySQL 的四种隔离级别
#### read uncommitted
    读未提交，一个事务可能读取到另一个事务还未提交而后又回滚的更改，产生 **脏读**
#### read committed
    读已提交，事务读取到的数据需是其他事务提交过后的。但一个事务多次读取同一条记录，期间被其他事务修改，使得数据前后不一致，产生**不可重复读**
#### repeatable read
    可重复读，事务多次读取同一数据，保证前后一致。但可能有**幻读**问题，比如做范围查询，然后其他事务插入或删除记录，导致再次查出记录数与前面不一致
#### serializable
    串行化，强制所有事务串行之行，避免并发性问题。使用表锁实现。

### 2.4 MVCC
    用于提升mysql并发读写性能，避免不必要的锁等待。
    原理：
        每一行记录都有三个隐藏字段：
            DB_TRX_ID：最后修改的事务id
            DB_ROLL_PTR：回滚指针，指向该行数据前一个版本的指针，指向undo log中的一条记录；通过此指针，可以向前找到历史版本，即**版本链**。
            DB_ROW_ID：行id，如果表没有主键，自动用此字段作为主键生成聚簇索引
            删除标记位：记录该行是否被删除
        undo log：
            MVCC 的版本存储仓库。 当删除和修改数据时，会存档一份在undo log中；新增数据时，会记录新增信息，用于在回滚时删除。
            保存了版本链
        read view：
            决定了当前事务能看到哪个版本的数据
            当事务执行快照读时，会生成一个 Read View。这个 Read View 包含了以下关键信息：
                m_ids：当前系统中活跃（未提交）的所有事务ID列表。
                min_trx_id：m_ids 中最小的事务ID。
                max_trx_id：系统中下一个将要分配的事务ID（即当前最大事务ID + 1）。
                creator_trx_id：创建这个 Read View 的事务ID
        通过一些判断逻辑，判断当前事务对其他事务的可见性
        判断逻辑如下：
            如果被访问版本的 DB_TRX_ID 等于 creator_trx_id，说明这是当前事务自己修改的，可见。
            如果被访问版本的 DB_TRX_ID 小于 min_trx_id，说明这个版本在 Read View 创建之前就已经提交了，可见。
            如果被访问版本的 DB_TRX_ID 大于等于 max_trx_id，说明这个版本是在 Read View 创建之后才开启的事务修改的，不可见。
            如果被访问版本的 DB_TRX_ID 在 min_trx_id 和 max_trx_id 之间，则需要判断 DB_TRX_ID 是否在 m_ids（活跃事务列表）中：
                如果在，说明创建 Read View 时，修改该版本的事务还未提交，该版本不可见。
                如果不在，说明创建 Read View 时，修改该版本的事务已经提交，该版本可见。

    MVCC 只在隔离级别为读已提交（RC）、可重复读（RR）两种级别下生效；
    在RC下，每次快照读都要新建read view； 在RR下，只会创建一次read view
    解决了： 脏读、不可重复读和快照读时的幻读，不能解决当前读时的幻读；
    不能解决： 不能解决写冲突，两事务同时修改一行记录，会被覆盖，即丢失更新；需要加锁解决。
        不能解决读取最新数据，如下述问题； 不能解决当前读时的幻读，需要使用临键锁来解决。
    问题：
        RR级别下，一个事务不会读取到其他事务提交的最新数据，而是读取到第一次快照读的旧数据，这保证了可重复读。
        这在某些场景下符合要求，比如银行对账业务，需要一致性快照，它不需要统计到新的转账数据；
        但是某些业务下不符合要求，比如扣减库存的场景，先查出来库存不为0，但是期间被其他事务扣减到了0，此事务再去查询库存就必须查询到最新数据，要不然就会出错。这种情况解决办法如下：
            加锁读（select for update) 会等待其他事务更新完毕，看到最新数据。
            临时改变隔离级别，改成RC，这样每次快照读都能看到最新数据
            优化事务： 把大事务改成多个小事务
    总结：
        MVCC 看作是数据库的 “默认模式”，它优雅地处理了大多数并发读场景，大幅提升了并发性能。
        而当遇到写冲突、需要强一致性读或防止幻读时，就需要 “锁”（比如行锁）来处理。

    -- 查看当前正在等待锁的事务
    SELECT * FROM information_schema.INNODB_LOCKS;
    SELECT * FROM information_schema.INNODB_LOCK_WAITS;

2.5 什么是临键锁：

2.5 什么是快照读和当前读
    **快照读 (Snapshot Read)**：指的是读取数据的历史版本快照，普通SELECT语句不会加锁，读的是事务开始时生成ReadView那一刻的数据版本，这样可以保证读写不冲突，并发性能好。
    **当前读 (Current Read)**：指的是读取数据的最新版本，并且在读取时会加锁，保证其他事务不能并发修改这行数据。像INSERT、UPDATE、DELETE这些写操作，以及SELECT ... FOR UPDATE（加写锁）、SELECT ... LOCK IN SHARE MODE（加读锁）都属于当前读。
   
    简单来说，不加锁的SELECT就是快照读，而加锁的读和所有的写操作都是当前读。

2.8 MySQL是如何解决幻读的?

MySQL InnoDB在默认的可重复读（Repeatable Read）隔离级别下，是通过两种方式来解决**幻读**问题的：

    **快照读**（普通的SELECT）：它通过 MVCC 机制来解决。在事务开始时会生成一个ReadView，整个事务期间都用这个ReadView。这样，即使其他事务在这期间插入了新的数据并提交了，因为新数据的事务ID不在这个ReadView的可见范围内，所以当前事务是读不到这些新数据的，也就避免了幻读。
    **当前读**（比如SELECT ... FOR UPDATE）：它通过 间隙锁（Gap Lock）和临键锁（Next-Key Lock） 来解决。当我们执行一个范围查询并加锁时，InnoDB不仅会锁住满足条件的记录本身（记录锁），还会锁住这些记录之间的“间隙”，防止其他事务在这个间隙里插入新的数据。这样一来，也就防止了幻读的发生


## 3.索引
### 3.1索引的种类
    普通索引、唯一索引、复合索引
    聚簇索引、非聚簇索引
    B+tree索引、哈希索引、全文索引

### 3.2 哪些字段适合建索引
    主键、外键，主键自动建立索引，外键在外键约束声明情况下自动建立索引。
    经常做where条件、join的字段、order by、group by 的字段，值得建立索引
    高选择性的字段适合建立索引，低选择性字段（比如性别、状态）不适合建立索引

    不适合建立索引的字段：
        需要频繁改动的字段，频繁更新索引会非常消耗性能
        很少被用于查询的字段
        数据量极小的表（<1万行)，全表扫描更快
        非常长的字段（超长varchar、text类型），考虑前缀索引
        低选择性字段

### 3.3 为什么使用B+tree做索引
    数据库查询时减少磁盘IO次数可以大量缩短查询时间。数据库索引存在于磁盘，B+tree的非叶子节点只存储索引，磁盘IO一次读取一页的数据可以包含很多索引值，所以B+tree的高度可以很矮，这样减少磁盘IO次数，比如一个三四层的B+tree，能支撑千万级别的数据量。其次，B+tree叶子节点一指针相互连接形成有序的双向链表，范围查询和排序查询非常高效。
    B+tree索引，非叶子节点可以缓存在内存中，叶子节点直接存储数据本身，一个叶子节点对应一个数据页，按页加载到内存，从中筛选记录。
        根页常驻内存
        中间节点页也会有缓存机制
        叶子节点需要磁盘io
### 3.3 什么最左匹配原则
    等值匹配、从左到右；范围中断、跳过失效

### 3.4 什么是覆盖索引和回表查询
    覆盖索引：
        一种查询优化的方式。当我们查询的数据列，正好在使用的那个非聚簇索引（二级索引）里都已经包含了，那就不需要再去主键索引里查找完整的行数据了。
    回表查询：
        当我们通过一个二级索引找到了目标数据的主键ID，但是查询的列里还包含其他数据，而这些数据在二级索引里没有，那么数据库就必须拿着这个主key，再去聚簇索引（主键索引）里把完整的行数据查出来，称为回表。
        回表时，是按照**MRR多范围读**，先将二级索引查出的主键id排序，再按照顺序访问数据页，可能有些id对应的数据存在于同一数据页，使用缓存机制，大大减少了磁盘臂的移动和随机I/O。

### 3.5 怎么创建联合索引，查询效率最高？
    基本的原则是：把区分度最高（选择性最好）的字段放在最左边。
    查看区分度：SELECT COUNT(DISTINCT column_name) / COUNT(*)

### 3.6 什么是索引下推？优点是什么？
    在索引层面就过滤掉了大量不满足条件的数据，从而大大减少了回表的次数，提升了查询性能。如复合索引的第二列，如果是等值查询、范围查询，都可以在二级索引出默认使用索引下推，过滤掉一些数据记录，但是如果是排序，就用不到索引下推了，即第二列索引失效

### 3.7 哪些情况索引会失效
    1）使用!= 或者 <> 导致索引失效
    2）类型不一致导致的索引失效
    3）函数或表达式导致的索引失效（比如where YEAR(col)=xxx, where id+1=100)
    4) 使用OR连接非索引列
    5）LIKE 的模式以 % 或 _ 开头时
    6）复合索引未使用最左前缀
    7）数据分布导致优化器认为全表扫描更快（按索引列查询会返回20%-30%以上的记录）
    8）对索引列使用 IS NULL 或 IS NOT NULL，当空值记录特别多或特别少时，可能不会使用索引
    排查手段：
        EXPLAIN + sql
        如果 key 为 NULL，则表示未使用索引。
        查看 type 列，如果为 ALL，则表示全表扫描。
        查看 Extra 列，如果出现 Using where（在存储引擎层后过滤），通常意味着没有很好地利用索引。
    
### 3.8 为什么官方建议使用自增长主键作为索引？
    自增id可以避免页分裂，增加id时，就在B+tree叶子节点最右边追加，满了就开辟新节点。如果有UUID，可能会插入到中间的节点，导致页分裂，非常消耗性能

## 4 锁
### 4.1 mysql的锁分哪几种
    按锁粒度：表锁、页锁、行锁（记录锁、间隙锁、临键锁）
    按兼容性：共享锁（即读锁）、互斥锁（又称排他锁、写锁）
    按加锁策略：乐观锁、悲观锁

    表锁：锁住整张表，同时只能有一个事务读写，并发性能差。不会出现死锁。MyIsam主要使用表锁
        加表锁的情况：
            当需要更新表中的大部分数据
            事务涉及到多张表，业务逻辑复杂，加表锁可以避免死锁。
    页锁：锁住一个数据页，粒度介于表锁和行锁之间。使用较少
    行锁：只锁住被操作的那一行或几行数据。粒度小、并发性能好，但实现复杂、开销大、加锁慢、可能发生死锁

    记录锁：精准地锁住某一条索引记录
        select... for update, update ... where ... , 触发记录锁
    间隙锁：它锁的是一个“间隙”，两个索引记录之间的一段范围，这个范围是开区间，不锁记录本身，可以防止其他事务在这个范围插入新数据。防止幻读
    **临键锁**：记录锁+间隙锁。它既锁住了记录本身，也锁住了记录前面的那个间隙，是一个左开右闭的区间。既能锁住记录，有能防止幻读。
        加锁逻辑：
            //TODO
            精确操作唯一索引，记录存在则加记录锁，不存在则加相邻两个索引值范围的间隙锁
            RR隔离级别下，

    读锁： 
        大家都可以读，但是只有获取到锁的才能写； select... lock in share mode
    写锁：
        只有自己能读写，其他人不能读写
        UPDATE、DELETE、INSERT这些操作会自动加X锁，我们也可以通过SELECT ... FOR UPDATE来手动加X锁

    悲观锁：
        总觉得数据随时会被别人修改，所以每次去操作数据之前，都会先加锁，把数据锁住，操作完了再释放。数据库里的行锁、表锁，SELECT ... FOR UPDATE这些都属于悲观锁的实现。
        适用场景：它适合写操作多、冲突比较激烈的场景，因为先加锁可以保证数据的一致性。

    乐观锁：
        总觉得数据一般不会被别人修改，所以操作数据时不加锁，而是在最后提交更新的时候，再去检查一下，看在我操作期间数据有没有被别人改过。
        实现方式：最常见的就是通过版本号（version）或者时间戳。在更新时，带上之前读到的版本号，UPDATE ... WHERE id=... AND version=...，如果version没变，就更新成功并把version加一；如果version变了，说明数据被改过了，就更新失败，然后由应用层面决定是重试还是报错。
        适用场景：它适合读操作多、写操作少的场景，可以避免加锁的开销，提高吞吐量

4.2 如何查看死锁日志，并解决线上MySQL死锁问题?
    查看死锁日志：SHOW ENGINE INNODB STATUS
        关注列：LATEST DETECTED DEADLOCK
            事务id、事务持有什么锁、事务正在等待的锁、正在执行的sql
            mysql回滚了哪个事务以解决死锁
    可能原因和解决办法：
        短期：如果业务卡住了，可以手动 KILL 掉持有锁的那个MySQL线程ID，让业务先恢复。
        长期：必须从根源上解决。分析死锁日志后，常见的原因和解决方案有：
            1）加锁顺序不一致：比如两个事务都想更新A表和B表，一个先锁A再锁B，另一个先锁B再锁A，就很容易死锁。解决方案是规范代码，让所有需要同时锁多张表的地方，都按相同的顺序来加锁。
            2）事务过长：一个事务里做了太多的操作，中间夹杂网络io或复杂的业务逻辑，导致持有锁的时间太长，增加了死锁的概率。解决方案是拆分大事务，让事务尽可能地简短。
            3）索引问题：如果SQL没有走索引，或者索引不合理，导致扫描了大量的行，加了不必要的锁，也容易造成死锁。解决方案是优化SQL，确保有合适的索引，减少锁的范围
        改进：
            业务代码捕获死锁异常，延时重试
            增加监控，定期查看死锁日志指标，发prometheus告警
            代码审查于压测
        
## 5 日志
### 5.1 Mysql的日志主要有哪几种，分别有什么用？
    undo log: 主要和事务的原子性有关。它记录数据的旧版本，事务依赖它进行回滚。另外，MVCC 里的多版本读，也会用到 undo log。
        作用：
            实现事务回滚和MVCC
    redo log: InnoDB 存储引擎层的物理日志，事务提交时，它记录了数据页做了哪些修改。如果数据库宕机导致某些事务修改的数据没有持久
        化，服务恢复后可以从redo log加载，并写入数据文件实现持久化。redo log 是一个环形结构。
        作用：
            数据持久化和崩溃恢复
        三种落盘策略（innodb_flush_log_at_trx_commit）： 1.直接落盘，数据安全； 2.写内存，redo log buffer(内存)，每秒落盘，性能最好，但mysql挂掉会丢失一秒的数据。3.折中，写os buffer，适时fsync落盘，在服
            务器宕机后会丢失数据
    bin log: Server 层生成的日志，主要用于备份和主从复制。它记录的是逻辑操作，比如一条 SQL 更新了哪条数据。事务提交时，相关的 binlog 会统一写
        入日志文件，后续从库就可以通过 binlog 来重放，实现主从同步。
        三种格式：
            statement：记录原始的sql。日志量较小，但可能出现数据不一致的情况，比如 UUID() 或 NOW()等函数，每次执行都是不同值。
            row：详细记录每一行修改前后的数据。数据更安全，不依赖上下文。但日志量会很大，尤其是批量操作时的日志。需要mysqlbinlog工具解析。
            mixed：上面两种模式的结合。
        作用：
            主从复制：主库（Master）产生binlog，从库（Slave）获取并重放这些binlog，从而实现主从数据同步。
            数据恢复：我们可以利用全量备份加上某个时间点之后的binlog，来实现基于时间点的精确数据恢复（Point-in-Time Recovery）。

### 5.2 什么是WAL技术,，有什么好处？
    Write-Ahead Logging，也就是“预写日志”
    对数据进行任何修改时，不会立刻去操作磁盘上的数据文件，因为随机I/O太慢了。而是先将这次“修改”这个事件本身，以日志的形式记录下来（也就是写入redo log），这个过程是顺序I/O，速度非常快。
    极大地提升了数据库的写入性能和响应速度，也为数据库提供了可靠的崩溃恢复能力。

### 5.7 binlog和redolog的不同点有哪些?
    所属层面不同：redo log是InnoDB存储引擎层特有的；而binlog是MySQL Server层实现的，所有存储引擎都可以使用。

    记录内容不同：redo log记录的是关于数据页的物理修改，比如“在0号表空间的100号数据页的88偏移量处写入'abc'”，它是物理日志。而binlog记录的是逻辑
        操作，比如“给表T的id=1这行的c字段更新为10”，或者是原始的SQL语句，它是逻辑日志。

    文件形式不同：redo log的文件大小是固定的，采用循环写的方式，后面的日志会覆盖掉前面已经被消费的日志。binlog则是追加写，一个文件写满了，会自动
        切换到下一个新文件，不会覆盖旧日志。

    核心作用不同：redo log的核心使命是保证崩溃恢复（crash-safe），让InnoDB引擎具备持久性。而binlog的核心使命则是用于主从复制和数据恢复。

### 5.9 什么是MySQL两阶段提交, 为什么需要两阶段提交?
    1）准备阶段（Prepare）：当InnoDB写完redo log后，它不直接提交事务，而是将redo log的状态设置为“prepare”。
    2）提交阶段（Commit）：之后，由执行器去写binlog。当binlog成功写入磁盘后，执行器再通知InnoDB，将redo log的状态从“prepare”改为“commit”，完成整个事务的提交
    为了保证redolog和binlog这两份日志在逻辑上是绝对一致的。

## 主从同步
### 6.1 MySQL主从同步实现原理是怎样的?
    依赖bin log实现
    1）主库记录变更：主库上所有对数据的修改操作，都会被记录到自己的Binlog（二进制日志）文件中。
    2）从库拉取日志：从库上有一个专门的I/O线程，会连接到主库，请求主库的Binlog。主库接到请求后，会把Binlog的内容推送给从库。从库的I/O线程拿到
        Binlog后，会把它写入到自己的一个叫中继日志（Relay Log）的文件里。
    3）从库重放日志：从库上还有一个SQL线程，它会去读取Relay Log里的内容，然后把那些在主库上执行过的SQL操作，在自己本地原封不动地再执行一遍，这样就保证了数据和主库一致

    不保证强一致性，保证最终一致性

### 6.2 主从同步有哪些作用？

主从同步的主要作用有这么几个：

    1）读写分离：让主库（Master）专门负责写操作，从库（Slave）负责读操作，这样可以分摊数据库的压力，提升整体性能。
    2）高可用和容灾：当主库发生故障时，可以快速地把一个从库提升为新的主库，保证服务的连续性。
    3）数据备份：从库可以作为主库的一个实时备份，避免数据丢失。

### 6.3 Mysql主从同步有几种方式？

    1）全同步复制：当主库执行完一个事务，并且所有从库都执行完该事务后，才给客户端返回成功。
    2）半同步复制：至少有一个从库执行完成后，就给客户端返回成功。
    3）异步复制：主库执行完后，立即返回成功，不关心从库是否执行完成。

    如果对数据安全性要求没那么高，可以把同步模式改成半同步复制或者异步复制。

### 6.4 MySQL主从同步延迟有哪些原因?

常见的原因有这么几种：

    1）从库机器性能差：有时候为了节省成本，从库的硬件配置比主库差，主库执行一个操作很快，但从库执行起来慢，时间一长延迟就累积起来了。
    2）从库压力大：在读写分离的架构下，主库只处理写请求，而从库可能要承担大量的读请求，如果读请求占用了大量的CPU资源，就会影响到同步日志的SQL线程的执行，导致延迟。
    3）主库有大事务：如果主库执行了一个非常大的事务，比如一次性更新或删除了几百万行数据，这个操作可能要执行几分钟。那么这个大事务的Binlog传到从库后，从库也要花同样长的时间去执行，这期间就产生了明显的延迟。
    4）网络延迟：主库和从库之间的网络不稳定或者带宽不足，导致Binlog传输不及时，也会造成延迟。
    5）单线程复制：在早期版本的MySQL中，从库的SQL线程是单线程的。如果主库的并发写入量很大，单线程的从库就可能跟不上主库的节奏。

    优化方案：
    1）开启并行复制，配置参数：slave_parallel_workers
    2）调整同步模式，如果对数据一致性要求没那么高，可以改成异步复制，主库写入性能更高
    3）修改刷盘机制，修改从库参数：
        sync_binlog = 0：表示从库自己的binlog（如果开启了的话）不立即刷盘，由操作系统决定。
        innodb_flush_log_at_trx_commit = 2：表示事务提交时，redo log只写到操作系统的缓存，每秒刷一次盘。
    4）避免大事务

    数据不一致：
        对于要求强一致的场景，可以强制读请求走到主库。
    其他一致性问题排查：
        定期使用 pt-table-checksum 等工具校验主从数据一致性，并使用 pt-table-sync 进行修复。


## 7 性能优化
### 7.1 怎样通过Explain工具分析SQL执行计划？
    把它加在SELECT语句前面，就可以看到MySQL优化器是怎么打算执行这条SQL的。输出结果里有几个非常关键的列需要关注：

        **id**：查询的序列号，id越大，优先级越高，越先执行。
        **select_type**：查询的类型，比如SIMPLE（简单查询）、JOIN、SUBQUERY等。
        **table**：正在访问哪张表。
        **type**：这是最重要的一个指标，表示访问类型，也就是找到数据的方式。性能从好到差依次是：system > const > eq_ref > ref > range > index > all。我们优化的目标，就是尽量让type达到range或以上，最差也要避免all（全表扫描）。
        possible_keys ：字段表示可能用到的索引；
        **key**：实际用到的索引。如果key是NULL，那就要检查为什么索引没生效了。
        **key_len**：表示用到的索引的长度。这个值可以帮助我们判断联合索引是否被完全利用了。
        **rows**：MySQL估算的，为了找到结果需要扫描的行数。这个值越小越好。
        **Extra**：包含了很多额外的重要信息。
            Using index：表示用到了覆盖索引，性能很好。
            Using where：表示在存储引擎层返回数据后，又在Server层进行了过滤。
            Using temporary：表示用到了临时表，通常在GROUP BY或ORDER BY时出现，性能很差，需要优化。
            Using filesort：表示进行了一次外部排序，说明ORDER BY的字段没有索引，性能也很差。
            Using index condition：表示用到了索引下推，是好的信号。

    通过综合分析这些信息，我们就能知道SQL的瓶颈在哪里，从而进行针对性的优化。

### 7.2 慢sql优化

### 7.3 深分页问题
    分页查询时，offset越大，查询效率会降低
    方法：
        1）游标分页
            通过 WHERE id < [上一页最后一条的id] 条件 limit 10
            性能极好，时间复杂度O（1），但只能一页一页往下翻，不能随机跳页
        2）使用覆盖索引
            如果排序的字段是索引，就可以先用排序字段分页查询出主键id，再去in查询。扫描过滤索引页比数据页快，因为每页的索引比数据行多。
            可以随机跳页。但是当offset极大时，还是会变慢
        3）业务降级
            禁止深分页：保留上一页\下一页，强制用户使用更多的查询条件来缩小结果集
            使用缓存：如果结果页比较静态，可以把前N页的结果缓存在redis
            使用Elasticsearch：Elasticsearch对分页有做优化

## 8 分库分表
### 8.1 什么情况下需要分库分表
    分库：主要解决的是数据库连接数和并发压力的问题。当业务量非常大，单一数据库实例的连接数已经达到上限，或者QPS太高导致CPU、IO成为瓶颈时，我们就需
        要考虑分库。把不同的业务模块拆分到不同的数据库实例上，每个实例承担一部分并发压力。
    分表：主要解决的是单表数据量过大导致的问题。当一张表的数据量达到千万甚至上亿级别时，对这张表的增删改查性能都会急剧下降，索引维护的成本也会变得很
        高。这时候，我们就需要对这张表进行分表，把数据分散到多张小表里，来提高查询和写入的性能。

### 8.2 分库分表有哪些实现方式?

    垂直拆分：
        垂直分库：是按照业务维度来拆分。比如一个电商系统，可以把订单相关的表放到订单库，用户相关的表放到用户库，商品相关的表放到商品库。每个库负责一个独立的业务模块。
        垂直分表：是针对一张表，把字段拆分到不同的表里。比如，把一个包含很多字段的大表，拆分成一个主表和一个扩展表。主表存放常用的热点核心字段，扩展表存放非热点或者比较大的字段（比如TEXT类型），这样可以提高主表的查询性能。

    水平拆分：
        也叫水平分表。这个是针对数据行的拆分。当单表数据量太大时，我们按照某种规则（比如取模、按范围、按时间等），把一张大表的数据分散到多个结构相同的子表中。比如，订单表可以按照用户ID取模，把一个用户的订单都落到同一张子表里。
    
### 8.3 分库分表后的问题
    1）全局id唯一问题
        分表后，如果继续采用id自增，全局上则会产生重复id
        解决： 
            雪花算法：主流方案
            redis/mongo 自增
            uuid：作为索引性能较差
            号段模式：
    2）跨分片join、排序与聚合问题

    3）分布式事务问题

    拆分成多个表后，怎么根据id或name查找数据
    取模法：取模决定查哪张表
    缓存法：按name查询时，根据缓存id和name的映射，就可以知道查哪张表
    基因法：将name用随机函数生成64bit的code，取最后n位（比如拆分位16张表就取4），称为基因，用来决定写哪张表，并追加到id生成code的最后面，这样按
        id或name查询都可以通过这个基因找到对应的表

    多key业务：
        缓存法
        冗余法：